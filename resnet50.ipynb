{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative paths of the image and annotation folders\n",
    "train_reid_path = r'dataset\\plain_re-ID\\atrw_reid_train'\n",
    "train_anno_reid_path = r'dataset\\plain_re-ID\\atrw_anno_reid_train\\reid_list_train.csv'\n",
    "\n",
    "test_reid_path = r'dataset\\plain_re-ID\\atrw_reid_test'\n",
    "test_anno_reid_path = r'dataset\\plain_re-ID\\atrw_anno_reid_test\\reid_list_test.csv'\n",
    "\n",
    "# Define the absolute paths of the image and annotation folders\n",
    "train_reid_path = os.path.abspath(train_reid_path)\n",
    "train_anno_reid_path = os.path.abspath(train_anno_reid_path)\n",
    "\n",
    "test_reid_path = os.path.abspath(test_reid_path)\n",
    "test_anno_reid_path = os.path.abspath(test_anno_reid_path)\n",
    "\n",
    "# load training dataset\n",
    "data = pd.read_csv(train_anno_reid_path, names=['id', 'image_number'])\n",
    "X = np.array(data['image_number'])\n",
    "y = np.array(data['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels=None, transform=None, target_transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from original IDs to sequential numbers\n",
    "# This step is to avoid target out of bound issues\n",
    "id_to_int = {tiger_id: i for i, tiger_id in enumerate(set(y))}\n",
    "int_to_id = {i: tiger_id for tiger_id, i in id_to_int.items()}\n",
    "\n",
    "def target_transform(tiger_id):\n",
    "    \"\"\"Transform the tiger_id to a sequential integer.\"\"\"\n",
    "    return id_to_int[tiger_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda file_path: os.path.join(train_reid_path, file_path)),  \n",
    "    transforms.Lambda(lambda abs_img_path: Image.open(abs_img_path).convert(\"RGB\")),\n",
    "    transforms.Resize((256, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_data_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda file_path: os.path.join(test_reid_path, file_path)),  \n",
    "    transforms.Lambda(lambda abs_img_path: Image.open(abs_img_path).convert(\"RGB\")),\n",
    "    transforms.Resize((256, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = MyDataset(data=X, labels=y, transform=data_transform, target_transform=target_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "\n",
    "# Freeze layers in the base model\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the fc layer to match the number of classes in dataset\n",
    "num_classes = len(set(y))\n",
    "resnet_model.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward, backward, and optimize\n",
    "        outputs = resnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save the model\n",
    "model_directory_path = os.path.abspath(r'model')\n",
    "model_path = os.path.join(model_directory_path, 'resnet50.pth')\n",
    "torch.save(resnet_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(test_anno_reid_path, names=['image_number'])\n",
    "X_test = np.array(test_data['image_number'])\n",
    "\n",
    "test_dataset = MyDataset(X_test, transform=test_data_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods for generating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader):\n",
    "    features_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if isinstance(data, tuple):\n",
    "                inputs = data[0]\n",
    "            else:  # Handles cases where data is just image\n",
    "                inputs = data\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            features_list.append(outputs)\n",
    "\n",
    "    features = torch.cat(features_list, dim=0)\n",
    "    return features\n",
    "\n",
    "def rank_gallery(query_feature, gallery_features):\n",
    "    distances = torch.norm(gallery_features - query_feature, dim=1)\n",
    "    return distances.argsort(descending=False).tolist()\n",
    "\n",
    "def filename_to_id(filename):\n",
    "    return int(filename.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "resnet50 = models.resnet50(pretrained=False) \n",
    "num_classes = len(set(y))\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "model_path = r\"model/resnet50.pth\"\n",
    "resnet50.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50.to(device)\n",
    "\n",
    "# Extract features from the pre-trained model\n",
    "features = extract_features(resnet50, test_loader)\n",
    "\n",
    "# Generate results\n",
    "filenames = test_data['image_number'].tolist()\n",
    "results = []\n",
    "for i, feature in enumerate(features):\n",
    "    query_feature = feature.unsqueeze(0)\n",
    "    \n",
    "    # Taking all features except the current query feature\n",
    "    gallery_features = torch.cat([features[:i], features[i+1:]], dim=0)\n",
    "    \n",
    "    # Extracting IDs from filenames except the current query\n",
    "    gallery_ids = [filename_to_id(filenames[j]) for j in range(len(filenames)) if j != i]\n",
    "\n",
    "    ranking = rank_gallery(query_feature, gallery_features)\n",
    "    ranked_ids = [gallery_ids[idx] for idx in ranking]\n",
    "    \n",
    "    results.append({\"query_id\": filename_to_id(filenames[i]), \"ans_ids\": ranked_ids})\n",
    "\n",
    "# results = []\n",
    "# for i, feature in enumerate(features):\n",
    "#     query_feature = feature.unsqueeze(0)\n",
    "    \n",
    "#     # Taking all features except the current query feature\n",
    "#     gallery_features = torch.cat([features[:i], features[i+1:]], dim=0)\n",
    "#     gallery_ids = list(range(i)) + list(range(i+1, len(features)))\n",
    "\n",
    "#     ranking = rank_gallery(query_feature, gallery_features)\n",
    "#     ranked_ids = [gallery_ids[idx] for idx in ranking]\n",
    "#     results.append({\"query_id\": i, \"ans_ids\": ranked_ids})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = r'output/resnet50_predictions_2.json'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amur_tiger_re-identificiation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
